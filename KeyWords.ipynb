{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getregex():\n",
    "    #Начало простого парсера для bib-файлов.\n",
    "    #Игнорирует библиографические записи, невходящие в fieldList\n",
    "    biginRegex = '(@'\n",
    "    typeRegex = r'\\S+)(\\{'\n",
    "    enRegex = r'\\{(.*)\\}'\n",
    "    endEnRegex = r',\\s*'\n",
    "    bibKeyRegex = r'\\S+)' + endEnRegex\n",
    "    \n",
    "    stFields = ['address','annote','author'      ,'booktitle'   ,'chapter','crossref',\n",
    "                'edition','editor','howpublished','institution' ,'journal','key',\n",
    "                'month'  ,'note'  ,'number'      ,'organization','pages'  ,'publisher',\n",
    "                'school' ,'series','title'       ,'volume' ,'year'\n",
    "               ]\n",
    "    \n",
    "    nonStFields = ['affiliation','abstract','doi'     ,'eid'     ,'contents','copyright',\n",
    "                   'ISBN'       ,'ISSN'    ,'keywords','language','location','LCCN',\n",
    "                   'mrnumber'   ,'price'   ,'size'    ,'URL'     ,'groups'\n",
    "                  ]\n",
    "    \n",
    "    fieldList = ['type', 'bib-key'] + sorted(stFields + nonStFields, key=str.lower)\n",
    "    fieldtup = tuple(fieldList)\n",
    "    \n",
    "    rentr = lambda i : '(?:(' + i + r'\\s*\\=\\s*' + r'\\{.*\\})' + r',\\s*)?'\n",
    "    ListRegex = [rentr(i) for i in fieldtup]\n",
    "    \n",
    "    fullEntryRegex = biginRegex + typeRegex + bibKeyRegex + '(?:' + '|'.join(ListRegex) + ')+\\}\\s*'\n",
    "    \n",
    "    return re.compile(fullEntryRegex, flags=re.IGNORECASE), fieldtup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFrame(fname):\n",
    "    with open(fname,\"r\",encoding='utf-8') as f:\n",
    "            filetext = f.read()\n",
    "            \n",
    "    regex, columnsTuple = getregex()\n",
    "    enries = regex.findall(filetext)\n",
    "    \n",
    "    del filetext, regex\n",
    "\n",
    "    data=pd.DataFrame(columns = columnsTuple)\n",
    "\n",
    "    typeregex = re.compile(r'@(\\S+)')\n",
    "    bibkeyregex = re.compile(r'\\{(\\S+)')\n",
    "    fieldregex = re.compile(r'(\\S+)\\s*\\=\\s*\\{(.*)\\}') #\\1 - column; \\2 - value\n",
    "\n",
    "    number =- 1\n",
    "    for i in enries:\n",
    "        number += 1\n",
    "        data.loc[number, 'type'] = typeregex.findall(i[0])[0]\n",
    "        data.loc[number, 'bib-key'] = bibkeyregex.findall(i[1])[0]\n",
    "        for j in i[2:]:\n",
    "            if len(j) > 0:\n",
    "                field = fieldregex.findall(j)\n",
    "                if field[0][1] == '':\n",
    "                    data.loc[number,field[0][0]] = np.nan\n",
    "                else:\n",
    "                    data.loc[number,field[0][0]] = field[0][1]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandata(frame):\n",
    "    \n",
    "    data=frame.copy()\n",
    "    \n",
    "    data.dropna(axis=1, how='all', inplace=True)\n",
    "    data.dropna(how='all', inplace=True)\n",
    "    \n",
    "    usefulcolumns = ['booktitle', 'title', 'author', 'keywords', 'doi', 'type']\n",
    "    usefuldata = data.reindex(columns=usefulcolumns)\n",
    "    usefuldata.dropna(subset=['title', 'author', 'keywords'], inplace=True)\n",
    "    usefuldata.drop_duplicates(ignore_index=True, inplace=True)\n",
    "    \n",
    "    del data\n",
    "    \n",
    "    usefuldata['author'] = usefuldata['author'].str.replace(r'\\{','')\n",
    "    usefuldata['author'] = usefuldata['author'].str.replace(r'\\}','')\n",
    "    usefuldata['author'] = usefuldata['author'].str.replace(r'\\sand\\s',';')\n",
    "    usefuldata['author'] = usefuldata['author'].str.replace(r'\\s+',' ')\n",
    "    \n",
    "    usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\$[^\\$]*\\$','')\n",
    "    usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\s*;\\s*',';')\n",
    "    usefuldata['keywords'] = usefuldata['keywords'].str.replace(r';+',';')\n",
    "    usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\s+',' ')\n",
    "    \n",
    "    return usefuldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countKeys(keyfields):\n",
    "    \n",
    "    keywords = list()\n",
    "    keylist = list()\n",
    "    \n",
    "    for i in keyfields:\n",
    "        a = i.lower()\n",
    "        a = re.sub(r'-', ' ', a)\n",
    "        keylist += a.split(';')    \n",
    "        \n",
    "    for i in keylist:\n",
    "        toks = i.split(' ')\n",
    "        if len(toks) == 1:\n",
    "                keywords.append(toks[0])\n",
    "        elif len(toks) > 1:\n",
    "            for j in range(len(toks)):\n",
    "                for k in range(1, len(toks) + 1):\n",
    "                    newkey=' '.join(toks[j:k])\n",
    "                    newkey=re.sub(r'^\\s+', '', newkey)\n",
    "                    newkey=re.sub(r'\\s+$', '', newkey)\n",
    "                    if newkey != '':\n",
    "                        keywords.append(newkey)\n",
    "    \n",
    "    keys = pd.Series(keywords)\n",
    "    keys = keys[keys != '']\n",
    "    keys = pd.Series(keys.value_counts(), name = 'number')\n",
    "    keys = pd.DataFrame(keys)\n",
    "    keys['key length'] = [len(i.split(' ')) for i in keys.index]\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = makeFrame('.input_data/all_article.bib')\n",
    "usefuldata = cleandata(data)\n",
    "del data\n",
    "keyfields = usefuldata['keywords']\n",
    "del usefuldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = countKeys(keyfields)\n",
    "keys = keys.sort_index()\n",
    "keys = keys[keys['key length'] > 1]\n",
    "keys = keys[keys['number'] > 4]\n",
    "keys.to_csv('.results/keycounter(key length more than 1 and number more than 4 and sorted keys).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
