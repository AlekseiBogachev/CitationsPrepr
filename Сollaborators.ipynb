{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getregex():\n",
    "    '''Начало простого парсера для bib-файлов.\n",
    "    Игнорирует библиографические записи, невходящие в fieldList'''\n",
    "    \n",
    "    biginRegex = '(@'\n",
    "    typeRegex = r'\\S+)(\\{'\n",
    "    enRegex = r'\\{(.*)\\}'\n",
    "    endEnRegex = r',\\s*'\n",
    "    bibKeyRegex = r'\\S+)' + endEnRegex\n",
    "    \n",
    "    stFields = ['address','annote','author'      ,'booktitle'   ,'chapter','crossref',\n",
    "                'edition','editor','howpublished','institution' ,'journal','key',\n",
    "                'month'  ,'note'  ,'number'      ,'organization','pages'  ,'publisher',\n",
    "                'school' ,'series','title'       ,'volume' ,'year'\n",
    "               ]\n",
    "    \n",
    "    nonStFields = ['affiliation','abstract','doi'     ,'eid'     ,'contents','copyright',\n",
    "                   'ISBN'       ,'ISSN'    ,'keywords','language','location','LCCN',\n",
    "                   'mrnumber'   ,'price'   ,'size'    ,'URL'     ,'groups'\n",
    "                  ]\n",
    "    \n",
    "    fieldList = ['type', 'bib-key'] + sorted(stFields + nonStFields, key=str.lower)\n",
    "    \n",
    "    fieldtup = tuple(fieldList)\n",
    "    rentr = lambda i: '(?:(' + i + r'\\s*\\=\\s*' + r'\\{.*\\})' + r',\\s*)?'\n",
    "    ListRegex = [rentr(i) for i in fieldtup]\n",
    "    fullEntryRegex = biginRegex + typeRegex + bibKeyRegex + '(?:' + '|'.join(ListRegex) + ')+\\}\\s*'\n",
    "    \n",
    "    return re.compile(fullEntryRegex, flags=re.IGNORECASE), fieldtup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFrame(fname):\n",
    "    with open(fname,\"r\",encoding='utf-8') as f:\n",
    "            filetext=f.read()\n",
    "    regex,columnsTuple=getregex()\n",
    "    enries=regex.findall(filetext)\n",
    "    \n",
    "    del filetext,regex\n",
    "\n",
    "    data=pd.DataFrame(columns=columnsTuple)\n",
    "\n",
    "    typeregex   = re.compile(r'@(\\S+)')\n",
    "    bibkeyregex = re.compile(r'\\{(\\S+)')\n",
    "    fieldregex  = re.compile(r'(\\S+)\\s*\\=\\s*\\{(.*)\\}') #\\1 - column; \\2 - value\n",
    "\n",
    "    number=-1\n",
    "    for i in enries:\n",
    "        number+=1\n",
    "        data.loc[number,'type']=typeregex.findall(i[0])[0]\n",
    "        data.loc[number,'bib-key']=bibkeyregex.findall(i[1])[0]\n",
    "        for j in i[2:]:\n",
    "            if len(j)>0:\n",
    "                field=fieldregex.findall(j)\n",
    "                if field[0][1] == '':\n",
    "                    data.loc[number,field[0][0]] = np.nan\n",
    "                else:\n",
    "                    data.loc[number,field[0][0]] = field[0][1]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandata(frame):\n",
    "    data = frame.copy()\n",
    "    data.dropna(axis=1, how='all', inplace=True)\n",
    "    data.dropna(how='all', inplace=True)\n",
    "    \n",
    "    usefulcolumns = ['booktitle', 'title', 'author', 'keywords', 'doi', 'type']\n",
    "    usefuldata = data.reindex(columns=usefulcolumns)\n",
    "    usefuldata.dropna(subset=['title', 'author', 'keywords'], inplace=True)\n",
    "    usefuldata.drop_duplicates(ignore_index=True, inplace=True)\n",
    "    \n",
    "    del data\n",
    "    \n",
    "    usefuldata['author'] = usefuldata['author'].str.replace(r'\\{','')\n",
    "    usefuldata['author'] = usefuldata['author'].str.replace(r'\\}','')\n",
    "    usefuldata['author'] = usefuldata['author'].str.replace(r'\\sand\\s',';')\n",
    "    usefuldata['author'] = usefuldata['author'].str.replace(r'\\s+',' ')\n",
    "    \n",
    "    usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\$[^\\$]*\\$','')\n",
    "    usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\s*;\\s*',';')\n",
    "    usefuldata['keywords'] = usefuldata['keywords'].str.replace(r';+',';')\n",
    "    usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\s+',' ')\n",
    "\n",
    "    return usefuldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makecolmatrix(kwlist, data):\n",
    "    usefuldata = data.copy()\n",
    "    \n",
    "    autorstable = usefuldata.reindex(columns=['author', 'keywords', 'doi'])\n",
    "    \n",
    "    del usefuldata\n",
    "    \n",
    "    kwlist = [i.replace(' ', '.') for i in kwlist]\n",
    "    kwregex = '(?:' + '|'.join(kwlist) + ')'\n",
    "    selauthors = autorstable[autorstable['keywords'].str.contains(kwregex)].reindex(columns=['doi','author'])\n",
    "    \n",
    "    del autorstable\n",
    "\n",
    "    aframe = pd.DataFrame(columns=['doi','author'])\n",
    "    for i in selauthors.index:\n",
    "        alist = selauthors.loc[i,'author'].split(';')\n",
    "        dlist = [selauthors.loc[i,'doi']] * len(alist)\n",
    "        dframe = pd.DataFrame({'doi':dlist, 'author':alist}, columns=['doi','author'])\n",
    "        aframe = aframe.append(dframe, ignore_index=True)\n",
    "    \n",
    "    del dframe\n",
    "    \n",
    "    aframe.drop_duplicates(ignore_index=True, inplace=True)\n",
    "    mcauthors = aframe['author'].value_counts()\n",
    "    doiarr = aframe['doi'].unique()\n",
    "    \n",
    "    adjacency_matrix = pd.DataFrame(np.zeros((len(mcauthors.index), len(mcauthors.index)), dtype=np.int32),\n",
    "                                    index=mcauthors.index, columns = mcauthors.index)\n",
    "    for i in doiarr:\n",
    "        coauthors = aframe[aframe['doi'].str.contains(i)]\n",
    "        cl = list(coauthors.loc[:,'author'])\n",
    "        if len(cl) > 1:\n",
    "            for j in cl[1:]:\n",
    "                adjacency_matrix.loc[cl[0], j] += 1\n",
    "                adjacency_matrix.loc[j, cl[0]] += 1\n",
    "    \n",
    "    for i in range(1, adjacency_matrix.shape[0]):\n",
    "        adjacency_matrix.iloc[i, range(i)] = 0\n",
    "        \n",
    "    return mcauthors, adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_adjacency_list(adjacency_matrix):\n",
    "    adjacency_list = adjacency_matrix.stack()\n",
    "    adjacency_list = adjacency_list.sort_values(ascending=False)\n",
    "    \n",
    "    l1 = [i[0] for i in adjacency_list.index]\n",
    "    l2 = [i[1] for i in adjacency_list.index]\n",
    "    \n",
    "    l3 = list(adjacency_list)\n",
    "    \n",
    "    indelen = len(l1)\n",
    "    \n",
    "    del adjacency_list\n",
    "    \n",
    "    newd = {'author':l1, 'coauthor':l2, 'nuber of articles':l3}\n",
    "    \n",
    "    del l1,l2,l3\n",
    "    \n",
    "    adjacency_list = pd.DataFrame(newd, columns=['author', 'coauthor', 'nuber of articles'],\n",
    "                                  index=np.arange(1, indelen+1, dtype=np.int32))\n",
    "    del newd\n",
    "    \n",
    "    adjacency_list = adjacency_list[adjacency_list['nuber of articles'] > 0]\n",
    "    \n",
    "    return adjacency_list.set_index(['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = makeFrame('.input_data/all_article.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksei\\AppData\\Local\\Temp/ipykernel_5248/877523305.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  usefuldata['author'] = usefuldata['author'].str.replace(r'\\{','')\n",
      "C:\\Users\\Aleksei\\AppData\\Local\\Temp/ipykernel_5248/877523305.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  usefuldata['author'] = usefuldata['author'].str.replace(r'\\}','')\n",
      "C:\\Users\\Aleksei\\AppData\\Local\\Temp/ipykernel_5248/877523305.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  usefuldata['author'] = usefuldata['author'].str.replace(r'\\sand\\s',';')\n",
      "C:\\Users\\Aleksei\\AppData\\Local\\Temp/ipykernel_5248/877523305.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  usefuldata['author'] = usefuldata['author'].str.replace(r'\\s+',' ')\n",
      "C:\\Users\\Aleksei\\AppData\\Local\\Temp/ipykernel_5248/877523305.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\$[^\\$]*\\$','')\n",
      "C:\\Users\\Aleksei\\AppData\\Local\\Temp/ipykernel_5248/877523305.py:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\s*;\\s*',';')\n",
      "C:\\Users\\Aleksei\\AppData\\Local\\Temp/ipykernel_5248/877523305.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  usefuldata['keywords'] = usefuldata['keywords'].str.replace(r';+',';')\n",
      "C:\\Users\\Aleksei\\AppData\\Local\\Temp/ipykernel_5248/877523305.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  usefuldata['keywords'] = usefuldata['keywords'].str.replace(r'\\s+',' ')\n"
     ]
    }
   ],
   "source": [
    "usefuldata = cleandata(data)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwlist = list()\n",
    "with open('.input_data/a_keys.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        kwlist.append(line.strip())\n",
    "\n",
    "mcauthors, adjacency_matrix = makecolmatrix(kwlist, usefuldata)\n",
    "\n",
    "del usefuldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пары, которые публиковались вместе более 8 раз\n",
    "bounds = adjacency_matrix.copy()\n",
    "bounds[adjacency_matrix < 8] = 0\n",
    "boundslist = make_adjacency_list(bounds)\n",
    "boundslist.to_csv('.results/strong_bounds_list.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
